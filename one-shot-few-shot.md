[‚¨ÖÔ∏è Voltar para o README](./README.md)

## üõ†Ô∏è One-shot vs. Few-shot Prompting: Um Exemplo Pr√°tico

#Nesta se√ß√£o, vamos ilustrar a diferen√ßa e a rela√ß√£o entre One-shot e Few-shot prompting usando um exemplo pr√°tico. Lembre-se que **One-shot prompting √© um caso espec√≠fico de Few-shot prompting**, onde exatamente um exemplo √© fornecido. O Few-shot prompting, de forma mais geral, refere-se ao uso de um pequeno n√∫mero de exemplos (tipicamente 2 a 5, mas pode ser mais).

**Tarefa Exemplo:** Classifica√ß√£o de Sentimento de Texto.
O objetivo √© que o modelo classifique um texto como "positivo", "negativo" ou "neutro".

---

### üîπ One-shot Prompting (1 Exemplo)

No One-shot prompting, fornecemos uma instru√ß√£o clara e **um √∫nico exemplo** para guiar o modelo.

**üìù Exemplo de Prompt One-shot:**

```
Classifique o sentimento do seguinte texto como positivo, negativo ou neutro.

Texto exemplo: "Eu realmente n√£o gostei da comida, estava fria e sem sabor."
Sentimento exemplo: negativo

Texto para classificar: "Este filme √© absolutamente fant√°stico, uma obra-prima!"
Sentimento:
```

**Explica√ß√£o do One-shot:**
O √∫nico exemplo ("Eu realmente n√£o gostei da comida..." levando a "negativo") ajuda o modelo a:

Entender o formato de sa√≠da esperado (neste caso, uma √∫nica palavra indicando o sentimento).
Ter uma refer√™ncia do tipo de an√°lise de sentimento solicitada.
Inferir que deve aplicar um racioc√≠nio similar ao novo texto.
Este m√©todo pode ser suficiente para tarefas onde o conceito √© relativamente claro para o modelo e o formato desejado √© simples.

### üîπ Few-shot Prompting (N > 1 Exemplos)

No Few-shot prompting, fornecemos uma instru√ß√£o clara e m√∫ltiplos exemplos. Isso pode ajudar o modelo a entender melhor nuances, diferentes casos de uso, e a generalizar de forma mais robusta.

**üìù Exemplo de Prompt Few-shot (2 Exemplos - Two-shot):**

```
Classifique o sentimento do seguinte texto como positivo, negativo ou neutro.

Texto exemplo 1: "Eu realmente n√£o gostei da comida, estava fria e sem sabor."
Sentimento exemplo 1: negativo

Texto exemplo 2: "O dia est√° agrad√°vel e o parque est√° lindo, aproveitei cada momento!"
Sentimento exemplo 2: positivo

Texto para classificar: "O relat√≥rio √© factual e direto ao ponto, sem opini√µes."
Sentimento:
```

**üìù Exemplo de Prompt Few-shot (3 Exemplos - Three-shot):**

```
Classifique o sentimento do seguinte texto como positivo, negativo ou neutro.

Texto exemplo 1: "Eu realmente n√£o gostei da comida, estava fria e sem sabor."
Sentimento exemplo 1: negativo

Texto exemplo 2: "O dia est√° agrad√°vel e o parque est√° lindo, aproveitei cada momento!"
Sentimento exemplo 2: positivo

Texto exemplo 3: "A reuni√£o ocorreu conforme o planejado, sem grandes intercorr√™ncias ou novidades."
Sentimento exemplo 3: neutro

Texto para classificar: "Este filme √© absolutamente fant√°stico, uma obra-prima!"
Sentimento:
```

**Explica√ß√£o do Few-shot (com N>1 exemplos):**

- Com m√∫ltiplos exemplos:
  - O modelo observa mais varia√ß√µes da tarefa. No exemplo de 3-shot, ele v√™ demonstra√ß√µes para "negativo", "positivo" e "neutro". Isso √© particularmente √∫til se a categoria "neutro", por exemplo, n√£o fosse √≥bvia apenas com a instru√ß√£o ou com um √∫nico exemplo.
  - Ajuda a obter um formato de sa√≠da mais consistente e aderente ao padr√£o desejado.
  - Aumenta a probabilidade de o modelo capturar a inten√ß√£o correta, especialmente se a tarefa tiver ambiguidades que um √∫nico exemplo n√£o conseguiria resolver completamente.
  - Pode guiar o modelo em tarefas que exigem um racioc√≠nio mais complexo ou distin√ß√µes sutis entre categorias.

---

### üîπ An√°lise Comparativa: One-shot vs. Few-shot

### Semelhan√ßas Fundamentais

- Ambos se baseiam no **aprendizado em contexto** (*in-context learning*): o modelo aprende a realizar a tarefa a partir das demonstra√ß√µes fornecidas diretamente no prompt, sem necessidade de re-treinamento (*fine-tuning*).
- O objetivo principal √© **guiar o modelo para a resposta desejada** em termos de conte√∫do, formato, estilo ou tipo de racioc√≠nio.

### Diferen√ßa Principal

- **N√∫mero de exemplos fornecidos:**
    - **One-shot:** Exatamente 1 exemplo.
    - **Few-shot (N > 1):** Mais de 1 exemplo (geralmente um n√∫mero pequeno como 2, 3, 5).

### Quando usar One-shot

- Tarefas mais simples e diretas, onde o modelo j√° tem uma boa compreens√£o subjacente.
- Quando o formato de sa√≠da √© f√°cil de demonstrar com um √∫nico exemplo.
- Para economizar tokens no prompt (prompts mais curtos, custos menores e lat√™ncia reduzida).
- Quando um bom exemplo √∫nico √© altamente representativo da tarefa.

### Quando usar Few-shot (N > 1)

- Tarefas mais complexas, com nuances ou que exigem racioc√≠nio mais elaborado.
- Para demonstrar diferentes categorias de sa√≠da, estilos de resposta ou formatos variados.
- Para aumentar a robustez e a precis√£o da resposta, especialmente se o One-shot n√£o estiver performando bem.
- Quando o modelo tem dificuldade em generalizar a partir de um √∫nico exemplo ou h√° risco de se fixar em alguma peculiaridade de um √∫nico exemplo.

### Considera√ß√µes Importantes para Ambos

- **Qualidade dos Exemplos:** Exemplos ruins, amb√≠guos ou inconsistentes levam a resultados ruins, independentemente de serem One-shot ou Few-shot. Os exemplos devem ser claros, corretos e an√°logos √† tarefa desejada.
- **Custo de Tokens:** Few-shot prompts s√£o mais longos e consomem mais tokens da janela de contexto do modelo, podendo ser uma limita√ß√£o ou fator de custo.
- **Esfor√ßo de Cria√ß√£o:** Elaborar m√∫ltiplos exemplos de alta qualidade pode exigir mais tempo e esfor√ßo.
- **Ordem dos Exemplos (para Few-shot):** A ordem dos exemplos pode, √†s vezes, influenciar o resultado.

### üìù Conclus√£o da Compara√ß√£o

A escolha entre One-shot e Few-shot (N > 1) envolve equilibrar a necessidade de orientar o modelo com o custo e a complexidade de fornecer exemplos. Uma boa pr√°tica √© come√ßar pela abordagem mais simples (Zero-shot), avan√ßar para One-shot se necess√°rio e, caso a performance ainda precise melhorar, utilizar Few-shot (N > 1). A experimenta√ß√£o √© essencial para determinar o n√∫mero ideal de exemplos para cada tarefa e modelo.
